{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize MNIST\n",
    "\n",
    "Converts the original MNIST dataset to a binarized black and white version thresholded by a chosen intensity 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitchgu/.pyenv/versions/3.6.3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from model import DCGAN\n",
    "import numpy as np\n",
    "import os\n",
    "NPY_DIR = 'npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(images):\n",
    "    for img in images:\n",
    "        plt.figure()\n",
    "        plt.imshow(img[:,:,0], cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/mnist\"\n",
    "\n",
    "# Load both train and test images and labels into a numpy byte array\n",
    "with open(os.path.join(data_dir, 'train-images-idx3-ubyte'), 'r') as fd:\n",
    "    trX_load = np.fromfile(file=fd, dtype=np.uint8)\n",
    "    \n",
    "with open(os.path.join(data_dir, 'train-labels-idx1-ubyte'), 'r') as fd:\n",
    "    trY_load = np.fromfile(file=fd, dtype=np.uint8)\n",
    "    \n",
    "with open(os.path.join(data_dir, 't10k-images-idx3-ubyte'), 'r') as fd:\n",
    "    teX_load = np.fromfile(file=fd, dtype=np.uint8)\n",
    "    \n",
    "with open(os.path.join(data_dir, 't10k-labels-idx1-ubyte'), 'r') as fd:\n",
    "    teY_load = np.fromfile(file=fd, dtype=np.uint8)\n",
    "\n",
    "\n",
    "# Cut off the first header bytes and reshape the rest into images\n",
    "trX = trX_load[16:].reshape((60000,28,28,1)).copy()\n",
    "trY = trY_load[8:].reshape((60000))\n",
    "teX = teX_load[16:].reshape((10000,28,28,1)).copy()\n",
    "teY = teY_load[8:].reshape((10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "th=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(inp, th):\n",
    "    return 255*(inp > th).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold the entire dataset and save into new IDX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX_th = threshold(trX, th)\n",
    "teX_th = threshold(teX, th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trX_load[16:] = trX_th.flatten()\n",
    "teX_load[16:] = teX_th.flatten()\n",
    "\n",
    "trX_load.tofile(os.path.join(data_dir, \"th-train-images-idx3-ubyte\"))\n",
    "teX_load.tofile(os.path.join(data_dir, \"th-t10k-images-idx3-ubyte\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show(trX[:1])\n",
    "show(trX_th[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some sample real and fake batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Dump 64 real thresholded images into samples1.npy\n",
    "trX_th[0:64].dump('npy/samples1.npy')\n",
    "trY[0:64].dump('npy/samples1_y.npy')\n",
    "\n",
    "# Dump uniform random images into samples2.npy\n",
    "rand = np.random.choice(256, (64,28,28,1)).astype(np.uint8)\n",
    "rand.dump('npy/samples2.npy')\n",
    "rand_y = np.random.choice(10, 64).astype(np.uint8)\n",
    "rand_y.dump('npy/samples2_y.npy')\n",
    "\n",
    "# Dump 64 real thresholded images with quadrant removed into samples1.npy\n",
    "chopped = trX_th[0:64].copy()\n",
    "chopped[:,7:21,7:21,:] = 0\n",
    "chopped.dump('npy/samples3.npy')\n",
    "trY[0:64].dump('npy/samples3_y.npy')\n",
    "\n",
    "# Dump black images into samples4.npy\n",
    "black = np.zeros((64,28,28,1)).astype(np.uint8)\n",
    "black.dump('npy/samples4.npy')\n",
    "black_y = np.random.choice(10, 64).astype(np.uint8)\n",
    "black_y.dump('npy/samples4_y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run them through the policy net (discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# Create DCGAN model\n",
    "dcgan = DCGAN(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/mnist_64_28_28/DCGAN.model-50502\n",
      " [*] Success to read DCGAN.model-50502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 50502)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcgan.load('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean real/fake value for samples1: 0.0\n",
      "Mean real/fake value for samples2: 0.0\n",
      "Mean real/fake value for samples3: 0.0\n",
      "Mean real/fake value for samples4: 0.00029755450668744743\n"
     ]
    }
   ],
   "source": [
    "for samples_fname in [\"samples1\", \"samples2\", \"samples3\", \"samples4\"]:\n",
    "    # Load samples from numpy file\n",
    "    samples = np.load(os.path.join(NPY_DIR, samples_fname + \".npy\"))\n",
    "    samples_y = np.load(os.path.join(NPY_DIR, samples_fname + \"_y.npy\"))\n",
    "\n",
    "    # Samples needs to be shape (64, 28, 28, 1)\n",
    "    # labels need to be in shape (64)\n",
    "    v, grad = dcgan.run_policy(samples, samples_y) # returns real/fake value and gradients\n",
    "\n",
    "    # Print mean value for 64 samples\n",
    "    print(\"Mean real/fake value for {}: {}\".format(samples_fname, np.mean(v)))\n",
    "    # Dump the gradients to a file (64, 28, 28, 1)\n",
    "    grad.dump(os.path.join(NPY_DIR, samples_fname + \"_grad.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grad = np.load(\"npy/samples2_grad.npy\")\n",
    "print(rand_y[:2])\n",
    "show(rand[:2])\n",
    "show(grad[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grad = np.load(\"npy/samples3_grad.npy\")\n",
    "n = 4\n",
    "print(trY[:n])\n",
    "show(chopped[:n])\n",
    "show(grad[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
